---
layout: default
title: 高性能服务端搭建笔记
---

本人从事服务端后台开发已经有四年时间了，期间有一些收获心得在本文中整理一下。  
首先在我看来，什么样的服务端才算是高性能的呢？作为一个处理在线任务的开发来说，低延时和高吞吐是衡量一个服务端性能好坏的关键指标。在我目前所在的公司中，一个项目时常的要关注的指标包括：P95，CPS、CPU、IO、可用性以及GC。可用性是根本，其他指标的波动最终都会反映到可用性上来。如下图所示：  
<img src="http://dbp-resource.cdn.bcebos.com/a1620f93-4200-9024-4be8-61a6751b1340/1243.png" width="800" height="500"/><br/>


本文的思路是先谈下技术选型，在技术选型的确定的基础之上，再进一步讨论如何优化。 
 
首先谈下RPC服务的选型，也就是客户端应该以何种方式与服务端来交互。就目前而言，我接触过两种方式：HTTP（使用jetty或者tomcat）和thrift。从更抽象一层来看，其实是HTTP和RPC的关系，这两者之间的关系知乎上有篇文章写得挺不错（[https://www.zhihu.com/question/41609070](https://www.zhihu.com/question/41609070)）。一般的来说，rpc是牺牲了可读性，来提升易用性和效率的，尤其是内部系统之间的调用，效率的重要性就更加凸显了。具体而言，我是用的是linkedIn公司推出的thrift，同类的还有谷歌推出的gRBC。这三者中数thrift的性能最佳，看网上有人对三种的测试结果进行比较，thrift服务端响应效率是grpc的两部，是http的十倍以上。在本文中暂不对这个性能差异进行深入钻研，只是想表明一个结论：thrift要高于HTTP。在我所了解的项目中，针对外部设备使用长连接来提升效率的，这个的原理暂时还没有了解，后续文章会挖掘出来。 

在这里顺便说下，thrift为什么效率要高一些呢？最终要的一个地方是节省了序列化和发序列的消耗，像其他的RPC使用JSON或者XML等协议传输，有很多多余的信息，thrift为了节省，把变量名都节省了而改用序号来代替，所以他的传输效率最好，序列化和反序列化的消耗最好。

 一旦我们选择了服务器的技术选型。接下来就开始选择服务端框架了。其实服务端框架的选择，一个因素就是你所使用的语言，以及对应框架被使用人数的多少。比如如果你选择用java开发，大概率会选择spring或者spring boot。如果是scala，play框架就是首选。在这方面性能比较我所知甚少。我在一家公司的时候，听说有个团队确认spring boot使用的核心线程池队列是无界队列，导致他们的服务发生了一次事故。从网上来看springboot是可以配置的，不清楚他们是不是因为是用了默认的配置而导致的。**不过这里也揭示了一个结论，对于高性能服务端而言，我们一般有意减小队列长度大小，而相应增加线程数量**。 但是这个是要有节制了，不是说吧队列长度较少成0，线程数量增加几百几千，这方面一般核心线程数不要过百，在CPU核数的2倍左右比较健康。 
 
如果你的返回值是个文件，无论是音频还是文本，总体来说以流式返回的效果要优于直接下发文件。  

作为服务端开发，我们首要的是保证系统任何情况下都能正常响应。但是对于核心服务，是不允许挂掉的，或者一旦全部挂掉就得有人要跑路的情形，必要的保护措施还是需要的。我所了解的比较的保护措施主要是限流和熔断。限流主要使用谷歌提供的guava包，熔断主要使用Hystrix，两者都并不复杂，在这里也不进行深入讨论。

还有一个重点要解释，如果你负责的系统对性能要求较高，那么使用异步来代替同步是个性价比非常高的选择。根据我个人的实战经验，同一个系统，单机在同步的情况下在QPS达到100的时候性能开始明显恶化，而使用异步的话，单机可以承受500的QPS甚至更高，这里再补充一个个人经验。如果你的系统压测单机可以承受1K的QPS，一般在生产环境下不允许超过700，在平时保持在300属于比较健康，当达到500的时候，就应该开始告警了，这就是357法则。个人使用了scala和java两种语言，java在1.8的时候对异步化编程还不是很好，但是scala简直就是为异步化而生，异步处理值得点赞，听说Go语言就继承了类似特性。异步的好处还要很多，比如不会因为某一个业务方迟迟没有返回而导致系统严重问题，因为同步的话会存在线程池耗尽的问题，而纯异步的话就不存在这个问题。  

本人使用开发语言最多的是java和scala，虽然不同但是却是同源的，他们都是JVM语言，而且语法上是兼容的。既然是java。先谈下gc。个人的经验，G1的效果要由于CMS，使用过ZGC，他的优化效果更好，目标是将GC停顿调整到10ms以下，近期会在生产环境下测试下是否如此神奇。  

在这些的基础上，接下来本人要介绍一些自己遇到问题的一些经验了。按照这样的设计，随着QPS的上升，我们的服务还是会抵挡不住流量，这个时候我们最容易想到的加缓存，这个地方的顺序是：集中缓存-> 本地文件-> 本地内存。关于如何使用集中缓存，在另一篇文章中我做过一些介绍，具体见：缓存在服务端的使用经验总结。但是每一种都有自己各自的优缺点。比如说集中缓存保持一致性已经比较难搞了，如果是本地缓存就更难了，甚至可以说没有十分靠谱的办法。另外过多的使用本地缓存，还会带来另外一个问题gc问题，这个解决起来比解决一致性还要头疼。**所以使用这个方案一定要节制，集中缓存满足要求就不要使用本地的，不要为了想象中的可能的慢而采取激进的做法**。缓存使用的好，是可以大大提升服务的性能的，因为一般性的缓存，单机承受十几万的QPS压力并不算大，这就解除了数据读取的压力。

在进行开发的时候，还有一个问题在这儿要提一下。打印日志一定要克制，不能因为害怕日后不好查问题，而无节制的打印日志。过多的打印日志，会影响gc，会占用服务IO，导致服务的性能下降，如下图所示就是我删除了一些无关日志之后，服务的负载下降了10%左右。

